num_layers: 2
hidden_size: 64
inner_size: 256
dropout_prob: 0.3
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
loss_type: 'CE'

plm_suffix: blair-roberta-base.feature
plm_size: 768
adaptor_dropout_prob: 0.2
adaptor_layers: [768,300,64]
embedding_size: 64

# plm_suffix: blair-roberta-large.feature
# plm_size: 1024
# adaptor_dropout_prob: 0.2
# adaptor_layers: [1024,300,64]
# embedding_size: 64

# plm_suffix: NV-Embed-v2.feature
# plm_size: 4096
# adaptor_dropout_prob: 0.2
# adaptor_layers: [4096,300,64]
# embedding_size: 64